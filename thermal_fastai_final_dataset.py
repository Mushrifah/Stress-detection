# -*- coding: utf-8 -*-
"""thermal_fastai_final_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yqVyyeknOQozIg4EjkbnFTNv29uxNCu2
"""

from fastai.vision import *

from google.colab import drive
drive.mount('/content/gdrive')

!ls

#/content/gdrive/My Drive/dataset.zip

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

import io


import zipfile
#https://drive.google.com/open?id=1aVVieDaek7T7ouia1VqVgrbosTP34KGr
file_id="1aVVieDaek7T7ouia1VqVgrbosTP34KGr"
downloaded=drive.CreateFile({'id':file_id})
downloaded.GetContentFile('Dataset.zip')
!unzip Dataset.zip

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext autoreload
# %autoreload 2
# %matplotlib inline

from fastai.vision import *
from fastai.metrics import error_rate

bs = 64  #batch size: if your GPU is running out of memory, set a smaller batch size, i.e 16
sz = 224 #image size
PATH = '/content/gdrive/My Drive/Dataset'

classes = []
for d in os.listdir(PATH):
    if os.path.isdir(os.path.join(PATH, d)) and not d.startswith('.'):
        classes.append(d) 
print ("There are ", len(classes), "classes:\n", classes)

for c in classes:
    print ("Class:", c)
    verify_images(os.path.join(PATH, c), delete=True);

np.random.seed(43)



data  = ImageDataBunch.from_folder(PATH, ds_tfms=get_transforms(flip_vert=True, max_rotate=50.0), size=sz, bs=bs, valid_pct=0.2).normalize(imagenet_stats)
print ("There are", len(data.train_ds), "training images and", len(data.valid_ds), "validation images." )

tfms=get_transforms()
data = (ImageList.from_folder(PATH)
.split_by_rand_pct(valid_pct=0.2)
.label_from_folder()
.transform(tfms,size=448)
.databunch()).normalize(imagenet_stats)

from sklearn.model_selection import StratifiedKFold

df=data.to_df()
df.head()

skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)

acc_val

acc_val=[]
for train_index, val_index in skf.split(df.index,df['y']):
  data_fold=(ImageList.from_df(df,PATH)
  .split_by_idxs(train_index,val_index)
  .label_from_df()
  .transform(tfms,size=224)
  .databunch(num_workers=0)).normalize(imagenet_stats)
  learn = cnn_learner(data_fold,models.resnet34,metrics=accuracy)
  learn.fit_one_cycle(4)
  loss,acc=learn.validate()
  acc_val.append(acc.numpy())


# for cross validation

kf = KFold(n_splits=2, random_state=379)
epochs = 6
lr = 1e-2
preds = []
for data.train_ds, data.valid_ds in kf.split(classes):
    data = create_databunch(data.valid_ds)
    learn = create_cnn(data, models.resnet34, metrics=[accuracy])
    learn.fit_one_cycle(epochs, slice(lr))
    learn.unfreeze()
    learn.fit_one_cycle(epochs, slice(lr/400, lr/4))
    learn.fit_one_cycle(epochs, slice(lr/800, lr/8))
    preds.append(learn.get_preds(ds_type=DatasetType.Test))

  

data.show_batch(rows=3, figsize=(7,8))



learn = cnn_learner(data, models.vgg16_bn)

learn.model

learn.metrics=[error_rate,
               accuracy,
               Precision(),
               Recall(),
               FBeta(),
               AUROC()]

#learn.fit_one_cycle(1)

learn.fit_one_cycle(5)


#learn.fit_one_cycle(3,max_lr=1e-5)



learn.summary()

learn.save('stage-1')

learn.export('a.pkl')

interp = ClassificationInterpretation.from_learner(learn)

interp = ClassificationInterpretation.from_learner(learn)

losses,idxs = interp.top_losses()

len(data.valid_ds)==len(losses)==len(idxs)

img = learn.data.train_ds[1][0]
learn.predict(img)

interp.plot_confusion_matrix(figsize=(6,4), dpi=100)

interp.plot_top_losses(9, figsize=(15,11), heatmap=False)

#unfreeze model

#learn.unfreeze()

#learn.fit_one_cycle(1)



from fastai import *
from fastai.vision import *

PATH = '/content/gdrive/My Drive/Dataset'

classes = [ 'stress','non-stress']

data2 = ImageDataBunch.single_from_classes(PATH, classes, ds_tfms=get_transforms(), size=224).normalize(imagenet_stats)

load_learner(PATH)

learn=create_cnn(data2, models.resnet34, metrics=error_rate)

learn=load_learner(PATH,'a.pkl')

str(pred_class)

type(pred_class)

pred_idx

#for output prediction
img = open_image("4.jpg")
pred_class,pred_idx,outputs = learn.predict(img)
img.show()
print ("It is a", pred_class,"plant")

#learn.lr_find()
#learn.recorder.plot()
#learn.recorder.plot_losses()



from google.colab import drive
drive.mount('/content/drive')

learn.load('stage-1')

classes = ['stress', 'non-stress']
data2 = ImageDataBunch.single_from_classes(path, classes, ds_tfms=get_transforms(), size=224).normalize(imagenet_stats)
learn = create_cnn(data2, models.resnet34)
#learn.load('stage-1')

path = '/content/drive/My Drive/best' #The path of your test image
ata  = ImageDataBunch.from_folder(path, ds_tfms=get_transforms(), size=224, bs=bs, valid_pct=0.2).normalize(imagenet_stats)

#test outputs
img = open_image(get_image_files(path)[2])
pred_class,pred_idx,outputs = learn.predict(img)
img.show()
print ("It is a", pred_class,"plant")

img = open_image(get_image_files(path)[5])
pred_class,pred_idx,outputs = learn.predict(img)
img.show()
print ("It is a", pred_class,"plant")

